1- I trimmed the index off of the UMI read leaving only the UMI (8 nucleotides)
	$ fastx_trimmer -f 7 -l 14 -z -Q 33 -i CGATGT_S1_L001_I1_001.fastq -o index_trimmed.fastq.gz

#? I would like to learn how to use a zipped file as input here 


2- I added the trimmed UMI to the beginning of both paried reads 
	$ paste -d '\0' <(echo; sed -n '1,${n;p;}' index_trimmed.fastq | sed G) ../Chr21rDNA/CGATGT_S1_L001_R1_001.fastq | sed '/^$/d' > CGATGT_S1_L001_IR1_001.fastq

	$ paste -d '\0' <(echo; sed -n '1,${n;p;}' index_trimmed.fastq | sed G) ../Chr21rDNA/CGATGT_S1_L001_R2_001.fastq | sed '/^$/d' > CGATGT_S1_L001_IR2_001.fastq

#? Again I would like to learn to read in zipped files and output zipped files


3- I used sftp and the put command to move the files to the tesla server


4- I used bamtools to move the UMI from the beginning of the read to the first line of the FASTQ. The following was submitted to the Tesla Queue in a shell doc. 
	UMI="NNNNNNNN"

	unproc_fastq="CGATGT_S1_L001_IR2_001.fastq.gz"

	umitools trim $unproc_fastq $UMI | gzip -c > IR2_umi.fq.gz

 
5- I used jay's bowtie scipt (align_script.sh) to align the paired ends to the human genome resulting in one file with both aligned paried reads. There is no identifier left of which pair they represent but both have UMI at the beginning of the read. This script organizes the bowtie2 command ($BT2_HOME/bowtie2 --local -x lambda_virus -U $BT2_HOME/example/reads/longreads.fq -S eg3.sam) output into files 


6- I used UMItools to remove duplicate umi reads
	$ umitools rmdup alignment.bam rmv_dup_alignment.bam > rmv_dup_alignment.bed


7- I needed to create a sorted alignment index before publishing on UCSC browser
	$ samtools index <aln.bam>


#8 I made both the bam and bai file permissions completely accessible
$ chmod 777 <file>

 
#9 I used samtools to convert the BAM file to a fastq file to count the number of reads
from 64,539,044 to 50,850,060



